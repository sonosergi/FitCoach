{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdec57e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pillow==8.1.0\n",
    "!pip install matplotlib==3.3.4\n",
    "!pip install numpy==1.19.3\n",
    "!pip install opencv-python==4.5.1.48\n",
    "!pip install tqdm==4.56.0\n",
    "!pip install requests==2.25.1\n",
    "\n",
    "!pip install mediapipe==0.8.3\n",
    "\n",
    "print('installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ceac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraciÃ³n del video de entrada y salida\n",
    "video_in = 'video.mp4'\n",
    "video_out = 'video_final.mp4'\n",
    "cap = cv2.VideoCapture(video_in)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(video_out, fourcc, fps, (width, height))\n",
    "\n",
    "# Procesamiento de cada cuadro del video\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        # Reshape image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(np.expand_dims(img, axis=0), 192,192)\n",
    "        input_image = tf.cast(img, dtype=tf.float32)\n",
    "    \n",
    "        # Setup input and output \n",
    "        input_details = interpreter.get_input_details()\n",
    "        output_details = interpreter.get_output_details()\n",
    "    \n",
    "        # Make predictions \n",
    "        interpreter.set_tensor(input_details[0]['index'], np.array(input_image))\n",
    "        interpreter.invoke()\n",
    "        keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "        # Rendering \n",
    "        draw_connections(frame, keypoints_with_scores, EDGES, 0.4)\n",
    "        draw_keypoints(frame, keypoints_with_scores, 0.4)\n",
    "    \n",
    "        out.write(frame)\n",
    "        cv2.imshow('MoveNet Lightning', frame)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae221c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullBodyPoseEmbedder(object):\n",
    "  \"\"\"Converts 3D pose landmarks into 3D embedding.\"\"\"\n",
    "\n",
    "  def __init__(self, torso_size_multiplier=2.5):\n",
    "    # Multiplier to apply to the torso to get minimal body size.\n",
    "    self._torso_size_multiplier = torso_size_multiplier\n",
    "\n",
    "    # Names of the landmarks as they appear in the prediction.\n",
    "    self._landmark_names = [\n",
    "        'nose',\n",
    "        'left_eye_inner', 'left_eye', 'left_eye_outer',\n",
    "        'right_eye_inner', 'right_eye', 'right_eye_outer',\n",
    "        'left_ear', 'right_ear',\n",
    "        'mouth_left', 'mouth_right',\n",
    "        'left_shoulder', 'right_shoulder',\n",
    "        'left_elbow', 'right_elbow',\n",
    "        'left_wrist', 'right_wrist',\n",
    "        'left_pinky_1', 'right_pinky_1',\n",
    "        'left_index_1', 'right_index_1',\n",
    "        'left_thumb_2', 'right_thumb_2',\n",
    "        'left_hip', 'right_hip',\n",
    "        'left_knee', 'right_knee',\n",
    "        'left_ankle', 'right_ankle',\n",
    "        'left_heel', 'right_heel',\n",
    "        'left_foot_index', 'right_foot_index',\n",
    "    ]\n",
    "\n",
    " def __call__(self, landmarks):\n",
    "    \"\"\"Normalizes pose landmarks and converts to embedding\n",
    "    \n",
    "    Args:\n",
    "      landmarks - NumPy array with 3D landmarks of shape (N, 3).\n",
    "\n",
    "    Result:\n",
    "      Numpy array with pose embedding of shape (M, 3) where `M` is the number of\n",
    "      pairwise distances defined in `_get_pose_distance_embedding`.\n",
    "    \"\"\"\n",
    "    assert landmarks.shape[0] == len(self._landmark_names), 'Unexpected number of landmarks: {}'.format(landmarks.shape[0])\n",
    "\n",
    "    # Get pose landmarks.\n",
    "    landmarks = np.copy(landmarks)\n",
    "\n",
    "    # Normalize landmarks.\n",
    "    landmarks = self._normalize_pose_landmarks(landmarks)\n",
    "\n",
    "    # Get embedding.\n",
    "    embedding = self._get_pose_distance_embedding(landmarks)\n",
    "\n",
    "    return embedding\n",
    "\n",
    "  def _normalize_pose_landmarks(self, landmarks):\n",
    "    \"\"\"Normalizes landmarks translation and scale.\"\"\"\n",
    "    landmarks = np.copy(landmarks)\n",
    "\n",
    "    # Normalize translation.\n",
    "    pose_center = self._get_pose_center(landmarks)\n",
    "    landmarks -= pose_center\n",
    "\n",
    "    # Normalize scale.\n",
    "    pose_size = self._get_pose_size(landmarks, self._torso_size_multiplier)\n",
    "    landmarks /= pose_size\n",
    "    # Multiplication by 100 is not required, but makes it eaasier to debug.\n",
    "    landmarks *= 100\n",
    "\n",
    "    return landmarks\n",
    "\n",
    "  def _get_pose_center(self, landmarks):\n",
    "    \"\"\"Calculates pose center as point between hips.\"\"\"\n",
    "    left_hip = landmarks[self._landmark_names.index('left_hip')]\n",
    "    right_hip = landmarks[self._landmark_names.index('right_hip')]\n",
    "    center = (left_hip + right_hip) * 0.5\n",
    "    return center\n",
    "\n",
    "  def _get_pose_size(self, landmarks, torso_size_multiplier):\n",
    "    \"\"\"Calculates pose size.\n",
    "    \n",
    "    It is the maximum of two values:\n",
    "      * Torso size multiplied by `torso_size_multiplier`\n",
    "      * Maximum distance from pose center to any pose landmark\n",
    "    \"\"\"\n",
    "    # This approach uses only 2D landmarks to compute pose size.\n",
    "    landmarks = landmarks[:, :2]\n",
    "\n",
    "    # Hips center.\n",
    "    left_hip = landmarks[self._landmark_names.index('left_hip')]\n",
    "    right_hip = landmarks[self._landmark_names.index('right_hip')]\n",
    "    hips = (left_hip + right_hip) * 0.5\n",
    "\n",
    "    # Shoulders center.\n",
    "    left_shoulder = landmarks[self._landmark_names.index('left_shoulder')]\n",
    "    right_shoulder = landmarks[self._landmark_names.index('right_shoulder')]\n",
    "    shoulders = (left_shoulder + right_shoulder) * 0.5\n",
    "\n",
    "    # Torso size as the minimum body size.\n",
    "    torso_size = np.linalg.norm(shoulders - hips)\n",
    "\n",
    "    # Max dist to pose center.\n",
    "    pose_center = self._get_pose_center(landmarks)\n",
    "    max_dist = np.max(np.linalg.norm(landmarks - pose_center, axis=1))\n",
    "\n",
    "    return max(torso_size * torso_size_multiplier, max_dist)\n",
    "\n",
    "  def _get_pose_distance_embedding(self, landmarks):\n",
    "    \"\"\"Converts pose landmarks into 3D embedding.\n",
    "\n",
    "    We use several pairwise 3D distances to form pose embedding. All distances\n",
    "    include X and Y components with sign. We differnt types of pairs to cover\n",
    "    different pose classes. Feel free to remove some or add new.\n",
    "    \n",
    "    Args:\n",
    "      landmarks - NumPy array with 3D landmarks of shape (N, 3).\n",
    "\n",
    "    Result:\n",
    "      Numpy array with pose embedding of shape (M, 3) where `M` is the number of\n",
    "      pairwise distances.\n",
    "    \"\"\"\n",
    "    embedding = np.array([\n",
    "        # One joint.\n",
    "\n",
    "        self._get_distance(\n",
    "            self._get_average_by_names(landmarks, 'left_hip', 'right_hip'),\n",
    "            self._get_average_by_names(landmarks, 'left_shoulder', 'right_shoulder')),\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_shoulder', 'left_elbow'),\n",
    "        self._get_distance_by_names(landmarks, 'right_shoulder', 'right_elbow'),\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_elbow', 'left_wrist'),\n",
    "        self._get_distance_by_names(landmarks, 'right_elbow', 'right_wrist'),\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_hip', 'left_knee'),\n",
    "        self._get_distance_by_names(landmarks, 'right_hip', 'right_knee'),\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_knee', 'left_ankle'),\n",
    "        self._get_distance_by_names(landmarks, 'right_knee', 'right_ankle'),\n",
    "\n",
    "        # Two joints.\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_shoulder', 'left_wrist'),\n",
    "        self._get_distance_by_names(landmarks, 'right_shoulder', 'right_wrist'),\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_hip', 'left_ankle'),\n",
    "        self._get_distance_by_names(landmarks, 'right_hip', 'right_ankle'),\n",
    "\n",
    "        # Four joints.\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_hip', 'left_wrist'),\n",
    "        self._get_distance_by_names(landmarks, 'right_hip', 'right_wrist'),\n",
    "\n",
    "        # Five joints.\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_shoulder', 'left_ankle'),\n",
    "        self._get_distance_by_names(landmarks, 'right_shoulder', 'right_ankle'),\n",
    "        \n",
    "        self._get_distance_by_names(landmarks, 'left_hip', 'left_wrist'),\n",
    "        self._get_distance_by_names(landmarks, 'right_hip', 'right_wrist'),\n",
    "\n",
    "        # Cross body.\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_elbow', 'right_elbow'),\n",
    "        self._get_distance_by_names(landmarks, 'left_knee', 'right_knee'),\n",
    "\n",
    "        self._get_distance_by_names(landmarks, 'left_wrist', 'right_wrist'),\n",
    "        self._get_distance_by_names(landmarks, 'left_ankle', 'right_ankle'),\n",
    "\n",
    "        # Body bent direction.\n",
    "\n",
    "        # self._get_distance(\n",
    "        #     self._get_average_by_names(landmarks, 'left_wrist', 'left_ankle'),\n",
    "        #     landmarks[self._landmark_names.index('left_hip')]),\n",
    "        # self._get_distance(\n",
    "        #     self._get_average_by_names(landmarks, 'right_wrist', 'right_ankle'),\n",
    "        #     landmarks[self._landmark_names.index('right_hip')]),\n",
    "    ])\n",
    "\n",
    "    return embedding\n",
    "\n",
    "  def _get_average_by_names(self, landmarks, name_from, name_to):\n",
    "    lmk_from = landmarks[self._landmark_names.index(name_from)]\n",
    "    lmk_to = landmarks[self._landmark_names.index(name_to)]\n",
    "    return (lmk_from + lmk_to) * 0.5\n",
    "\n",
    "  def _get_distance_by_names(self, landmarks, name_from, name_to):\n",
    "    lmk_from = landmarks[self._landmark_names.index(name_from)]\n",
    "    lmk_to = landmarks[self._landmark_names.index(name_to)]\n",
    "    return self._get_distance(lmk_from, lmk_to)\n",
    "\n",
    "  def _get_distance(self, lmk_from, lmk_to):\n",
    "    return lmk_to - lmk_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseSample(object):\n",
    "\n",
    "  def __init__(self, name, landmarks, class_name, embedding):\n",
    "    self.name = name\n",
    "    self.landmarks = landmarks\n",
    "    self.class_name = class_name\n",
    "    \n",
    "    self.embedding = embedding\n",
    "\n",
    "\n",
    "class PoseSampleOutlier(object):\n",
    "\n",
    "  def __init__(self, sample, detected_class, all_classes):\n",
    "    self.sample = sample\n",
    "    self.detected_class = detected_class\n",
    "    self.all_classes = all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class PoseClassifier(object):\n",
    "  \"\"\"Classifies pose landmarks.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               pose_samples_folder,\n",
    "               pose_embedder,\n",
    "               file_extension='csv',\n",
    "               file_separator=',',\n",
    "               n_landmarks=33,\n",
    "               n_dimensions=3,\n",
    "               top_n_by_max_distance=30,\n",
    "               top_n_by_mean_distance=10,\n",
    "               axes_weights=(1., 1., 0.2)):\n",
    "    self._pose_embedder = pose_embedder\n",
    "    self._n_landmarks = n_landmarks\n",
    "    self._n_dimensions = n_dimensions\n",
    "    self._top_n_by_max_distance = top_n_by_max_distance\n",
    "    self._top_n_by_mean_distance = top_n_by_mean_distance\n",
    "    self._axes_weights = axes_weights\n",
    "\n",
    "    self._pose_samples = self._load_pose_samples(pose_samples_folder,\n",
    "                                                 file_extension,\n",
    "                                                 file_separator,\n",
    "                                                 n_landmarks,\n",
    "                                                 n_dimensions,\n",
    "                                                 pose_embedder)\n",
    "\n",
    "  def _load_pose_samples(self,\n",
    "                         pose_samples_folder,\n",
    "                         file_extension,\n",
    "                         file_separator,\n",
    "                         n_landmarks,\n",
    "                         n_dimensions,\n",
    "                         pose_embedder):\n",
    "    \"\"\"Loads pose samples from a given folder.\n",
    "    \n",
    "    Required folder structure:\n",
    "      neutral_standing.csv\n",
    "      pushups_down.csv\n",
    "      pushups_up.csv\n",
    "      squats_down.csv\n",
    "      ...\n",
    "\n",
    "    Required CSV structure:\n",
    "      sample_00001,x1,y1,z1,x2,y2,z2,....\n",
    "      sample_00002,x1,y1,z1,x2,y2,z2,....\n",
    "      ...\n",
    "    \"\"\"\n",
    "    # Each file in the folder represents one pose class.\n",
    "    file_names = [name for name in os.listdir(pose_samples_folder) if name.endswith(file_extension)]\n",
    "\n",
    "    pose_samples = []\n",
    "    for file_name in file_names:\n",
    "      # Use file name as pose class name.\n",
    "      class_name = file_name[:-(len(file_extension) + 1)]\n",
    "      \n",
    "      # Parse CSV.\n",
    "      with open(os.path.join(pose_samples_folder, file_name)) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=file_separator)\n",
    "        for row in csv_reader:\n",
    "          assert len(row) == n_landmarks * n_dimensions + 1, 'Wrong number of values: {}'.format(len(row))\n",
    "          landmarks = np.array(row[1:], np.float32).reshape([n_landmarks, n_dimensions])\n",
    "          pose_samples.append(PoseSample(\n",
    "              name=row[0],\n",
    "              landmarks=landmarks,\n",
    "              class_name=class_name,\n",
    "              embedding=pose_embedder(landmarks),\n",
    "          ))\n",
    "\n",
    "    return pose_samples\n",
    "\n",
    "  def find_pose_sample_outliers(self):\n",
    "    \"\"\"Classifies each sample against the entire database.\"\"\"\n",
    "    # Find outliers in target poses\n",
    "    outliers = []\n",
    "    for sample in self._pose_samples:\n",
    "      # Find nearest poses for the target one.\n",
    "      pose_landmarks = sample.landmarks.copy()\n",
    "      pose_classification = self.__call__(pose_landmarks)\n",
    "      class_names = [class_name for class_name, count in pose_classification.items() if count == max(pose_classification.values())]\n",
    "\n",
    "      # Sample is an outlier if nearest poses have different class or more than\n",
    "      # one pose class is detected as nearest.\n",
    "      if sample.class_name not in class_names or len(class_names) != 1:\n",
    "        outliers.append(PoseSampleOutlier(sample, class_names, pose_classification))\n",
    "\n",
    "    return outliers\n",
    "\n",
    "  def __call__(self, pose_landmarks):\n",
    "    \"\"\"Classifies given pose.\n",
    "\n",
    "    Classification is done in two stages:\n",
    "      * First we pick top-N samples by MAX distance. It allows to remove samples\n",
    "        that are almost the same as given pose, but has few joints bent in the\n",
    "        other direction.\n",
    "      * Then we pick top-N samples by MEAN distance. After outliers are removed\n",
    "        on a previous step, we can pick samples that are closes on average.\n",
    "    \n",
    "    Args:\n",
    "      pose_landmarks: NumPy array with 3D landmarks of shape (N, 3).\n",
    "\n",
    "    Returns:\n",
    "      Dictionary with count of nearest pose samples from the database. Sample:\n",
    "        {\n",
    "          'pushups_down': 8,\n",
    "          'pushups_up': 2,\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Check that provided and target poses have the same shape.\n",
    "    assert pose_landmarks.shape == (self._n_landmarks, self._n_dimensions), 'Unexpected shape: {}'.format(pose_landmarks.shape)\n",
    "\n",
    "    # Get given pose embedding.\n",
    "    pose_embedding = self._pose_embedder(pose_landmarks)\n",
    "    flipped_pose_embedding = self._pose_embedder(pose_landmarks * np.array([-1, 1, 1]))\n",
    "\n",
    "    # Filter by max distance.\n",
    "    #\n",
    "    # That helps to remove outliers - poses that are almost the same as the\n",
    "    # given one, but has one joint bent into another direction and actually\n",
    "    # represnt a different pose class.\n",
    "    max_dist_heap = []\n",
    "    for sample_idx, sample in enumerate(self._pose_samples):\n",
    "      max_dist = min(\n",
    "          np.max(np.abs(sample.embedding - pose_embedding) * self._axes_weights),\n",
    "          np.max(np.abs(sample.embedding - flipped_pose_embedding) * self._axes_weights),\n",
    "      )\n",
    "      max_dist_heap.append([max_dist, sample_idx])\n",
    "\n",
    "    max_dist_heap = sorted(max_dist_heap, key=lambda x: x[0])\n",
    "    max_dist_heap = max_dist_heap[:self._top_n_by_max_distance]\n",
    "\n",
    "    # Filter by mean distance.\n",
    "    #\n",
    "    # After removing outliers we can find the nearest pose by mean distance.\n",
    "    mean_dist_heap = []\n",
    "    for _, sample_idx in max_dist_heap:\n",
    "      sample = self._pose_samples[sample_idx]\n",
    "      mean_dist = min(\n",
    "          np.mean(np.abs(sample.embedding - pose_embedding) * self._axes_weights),\n",
    "          np.mean(np.abs(sample.embedding - flipped_pose_embedding) * self._axes_weights),\n",
    "      )\n",
    "      mean_dist_heap.append([mean_dist, sample_idx])\n",
    "\n",
    "    mean_dist_heap = sorted(mean_dist_heap, key=lambda x: x[0])\n",
    "    mean_dist_heap = mean_dist_heap[:self._top_n_by_mean_distance]\n",
    "\n",
    "    # Collect results into map: (class_name -> n_samples)\n",
    "    class_names = [self._pose_samples[sample_idx].class_name for _, sample_idx in mean_dist_heap]\n",
    "    result = {class_name: class_names.count(class_name) for class_name in set(class_names)}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d9b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMADictSmoothing(object):\n",
    "  \"\"\"Smoothes pose classification.\"\"\"\n",
    "\n",
    "  def __init__(self, window_size=10, alpha=0.2):\n",
    "    self._window_size = window_size\n",
    "    self._alpha = alpha\n",
    "\n",
    "    self._data_in_window = []\n",
    "\n",
    "  def __call__(self, data):\n",
    "    \"\"\"Smoothes given pose classification.\n",
    "\n",
    "    Smoothing is done by computing Exponential Moving Average for every pose\n",
    "    class observed in the given time window. Missed pose classes arre replaced\n",
    "    with 0.\n",
    "    \n",
    "    Args:\n",
    "      data: Dictionary with pose classification. Sample:\n",
    "          {\n",
    "            'pushups_down': 8,\n",
    "            'pushups_up': 2,\n",
    "          }\n",
    "\n",
    "    Result:\n",
    "      Dictionary in the same format but with smoothed and float instead of\n",
    "      integer values. Sample:\n",
    "        {\n",
    "          'pushups_down': 8.3,\n",
    "          'pushups_up': 1.7,\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Add new data to the beginning of the window for simpler code.\n",
    "    self._data_in_window.insert(0, data)\n",
    "    self._data_in_window = self._data_in_window[:self._window_size]\n",
    "\n",
    "    # Get all keys.\n",
    "    keys = set([key for data in self._data_in_window for key, _ in data.items()])\n",
    "\n",
    "    # Get smoothed values.\n",
    "    smoothed_data = dict()\n",
    "    for key in keys:\n",
    "      factor = 1.0\n",
    "      top_sum = 0.0\n",
    "      bottom_sum = 0.0\n",
    "      for data in self._data_in_window:\n",
    "        value = data[key] if key in data else 0.0\n",
    "\n",
    "        top_sum += factor * value\n",
    "        bottom_sum += factor\n",
    "\n",
    "        # Update factor.\n",
    "        factor *= (1.0 - self._alpha)\n",
    "\n",
    "      smoothed_data[key] = top_sum / bottom_sum\n",
    "\n",
    "    return smoothed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d89201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepetitionCounter(object):\n",
    "  \"\"\"Counts number of repetitions of given target pose class.\"\"\"\n",
    "\n",
    "  def __init__(self, class_name, enter_threshold=6, exit_threshold=4):\n",
    "    self._class_name = class_name\n",
    "\n",
    "    # If pose counter passes given threshold, then we enter the pose.\n",
    "    self._enter_threshold = enter_threshold\n",
    "    self._exit_threshold = exit_threshold\n",
    "\n",
    "    # Either we are in given pose or not.\n",
    "    self._pose_entered = False\n",
    "\n",
    "    # Number of times we exited the pose.\n",
    "    self._n_repeats = 0\n",
    "\n",
    "  @property\n",
    "  def n_repeats(self):\n",
    "    return self._n_repeats\n",
    "\n",
    "  def __call__(self, pose_classification):\n",
    "    \"\"\"Counts number of repetitions happend until given frame.\n",
    "\n",
    "    We use two thresholds. First you need to go above the higher one to enter\n",
    "    the pose, and then you need to go below the lower one to exit it. Difference\n",
    "    between the thresholds makes it stable to prediction jittering (which will\n",
    "    cause wrong counts in case of having only one threshold).\n",
    "    \n",
    "    Args:\n",
    "      pose_classification: Pose classification dictionary on current frame.\n",
    "        Sample:\n",
    "          {\n",
    "            'pushups_down': 8.3,\n",
    "            'pushups_up': 1.7,\n",
    "          }\n",
    "\n",
    "    Returns:\n",
    "      Integer counter of repetitions.\n",
    "    \"\"\"\n",
    "    # Get pose confidence.\n",
    "    pose_confidence = 0.0\n",
    "    if self._class_name in pose_classification:\n",
    "      pose_confidence = pose_classification[self._class_name]\n",
    "\n",
    "    # On the very first frame or if we were out of the pose, just check if we\n",
    "    # entered it on this frame and update the state.\n",
    "    if not self._pose_entered:\n",
    "      self._pose_entered = pose_confidence > self._enter_threshold\n",
    "      return self._n_repeats\n",
    "\n",
    "    # If we were in the pose and are exiting it, then increase the counter and\n",
    "    # update the state.\n",
    "    if pose_confidence < self._exit_threshold:\n",
    "      self._n_repeats += 1\n",
    "      self._pose_entered = False\n",
    "\n",
    "    return self._n_repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc2a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "import requests\n",
    "\n",
    "class PoseClassificationVisualizer(object):\n",
    "  \"\"\"Keeps track of claassifcations for every frame and renders them.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               class_name,\n",
    "               plot_location_x=0.05,\n",
    "               plot_location_y=0.05,\n",
    "               plot_max_width=0.4,\n",
    "               plot_max_height=0.4,\n",
    "               plot_figsize=(9, 4),\n",
    "               plot_x_max=None,\n",
    "               plot_y_max=None,\n",
    "               counter_location_x=0.85,\n",
    "               counter_location_y=0.05,\n",
    "               counter_font_path='https://github.com/googlefonts/roboto/blob/main/src/hinted/Roboto-Regular.ttf?raw=true',\n",
    "               counter_font_color='red',\n",
    "               counter_font_size=0.15):\n",
    "    self._class_name = class_name\n",
    "    self._plot_location_x = plot_location_x\n",
    "    self._plot_location_y = plot_location_y\n",
    "    self._plot_max_width = plot_max_width\n",
    "    self._plot_max_height = plot_max_height\n",
    "    self._plot_figsize = plot_figsize\n",
    "    self._plot_x_max = plot_x_max\n",
    "    self._plot_y_max = plot_y_max\n",
    "    self._counter_location_x = counter_location_x\n",
    "    self._counter_location_y = counter_location_y\n",
    "    self._counter_font_path = counter_font_path\n",
    "    self._counter_font_color = counter_font_color\n",
    "    self._counter_font_size = counter_font_size\n",
    "\n",
    "    self._counter_font = None\n",
    "\n",
    "    self._pose_classification_history = []\n",
    "    self._pose_classification_filtered_history = []\n",
    "\n",
    "  def __call__(self,\n",
    "               frame,\n",
    "               pose_classification,\n",
    "               pose_classification_filtered,\n",
    "               repetitions_count):\n",
    "    \"\"\"Renders pose classifcation and counter until given frame.\"\"\"\n",
    "    # Extend classification history.\n",
    "    self._pose_classification_history.append(pose_classification)\n",
    "    self._pose_classification_filtered_history.append(pose_classification_filtered)\n",
    "\n",
    "    # Output frame with classification plot and counter.\n",
    "    output_img = Image.fromarray(frame)\n",
    "\n",
    "    output_width = output_img.size[0]\n",
    "    output_height = output_img.size[1]\n",
    "\n",
    "    # Draw the plot.\n",
    "    img = self._plot_classification_history(output_width, output_height)\n",
    "    img.thumbnail((int(output_width * self._plot_max_width),\n",
    "                   int(output_height * self._plot_max_height)),\n",
    "                  Image.ANTIALIAS)\n",
    "    output_img.paste(img,\n",
    "                     (int(output_width * self._plot_location_x),\n",
    "                      int(output_height * self._plot_location_y)))\n",
    "\n",
    "    # Draw the count.\n",
    "    output_img_draw = ImageDraw.Draw(output_img)\n",
    "    if self._counter_font is None:\n",
    "      font_size = int(output_height * self._counter_font_size)\n",
    "      font_request = requests.get(self._counter_font_path, allow_redirects=True)\n",
    "      self._counter_font = ImageFont.truetype(io.BytesIO(font_request.content), size=font_size)\n",
    "    output_img_draw.text((output_width * self._counter_location_x,\n",
    "                          output_height * self._counter_location_y),\n",
    "                         str(repetitions_count),\n",
    "                         font=self._counter_font,\n",
    "                         fill=self._counter_font_color)\n",
    "\n",
    "    return output_img\n",
    "\n",
    "  def _plot_classification_history(self, output_width, output_height):\n",
    "    fig = plt.figure(figsize=self._plot_figsize)\n",
    "\n",
    "    for classification_history in [self._pose_classification_history,\n",
    "                                   self._pose_classification_filtered_history]:\n",
    "      y = []\n",
    "      for classification in classification_history:\n",
    "        if classification is None:\n",
    "          y.append(None)\n",
    "        elif self._class_name in classification:\n",
    "          y.append(classification[self._class_name])\n",
    "        else:\n",
    "          y.append(0)\n",
    "      plt.plot(y, linewidth=7)\n",
    "\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Confidence')\n",
    "    plt.title('Classification history for `{}`'.format(self._class_name))\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    if self._plot_y_max is not None:\n",
    "      plt.ylim(top=self._plot_y_max)\n",
    "    if self._plot_x_max is not None:\n",
    "      plt.xlim(right=self._plot_x_max)\n",
    "\n",
    "    # Convert plot to image.\n",
    "    buf = io.BytesIO()\n",
    "    dpi = min(\n",
    "        output_width * self._plot_max_width / float(self._plot_figsize[0]),\n",
    "        output_height * self._plot_max_height / float(self._plot_figsize[1]))\n",
    "    fig.savefig(buf, dpi=dpi)\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    plt.close()\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
    "from mediapipe.python.solutions import pose as mp_pose\n",
    "\n",
    "\n",
    "class BootstrapHelper(object):\n",
    "  \"\"\"Helps to bootstrap images and filter pose samples for classification.\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               images_in_folder,\n",
    "               images_out_folder,\n",
    "               csvs_out_folder):\n",
    "    self._images_in_folder = images_in_folder\n",
    "    self._images_out_folder = images_out_folder\n",
    "    self._csvs_out_folder = csvs_out_folder\n",
    "\n",
    "    # Get list of pose classes and print image statistics.\n",
    "    self._pose_class_names = sorted([n for n in os.listdir(self._images_in_folder) if not n.startswith('.')])\n",
    "    \n",
    "  def bootstrap(self, per_pose_class_limit=None):\n",
    "    \"\"\"Bootstraps images in a given folder.\n",
    "    \n",
    "    Required image in folder (same use for image out folder):\n",
    "      pushups_up/\n",
    "        image_001.jpg\n",
    "        image_002.jpg\n",
    "        ...\n",
    "      pushups_down/\n",
    "        image_001.jpg\n",
    "        image_002.jpg\n",
    "        ...\n",
    "      ...\n",
    "\n",
    "    Produced CSVs out folder:\n",
    "      pushups_up.csv\n",
    "      pushups_down.csv\n",
    "\n",
    "    Produced CSV structure with pose 3D landmarks:\n",
    "      sample_00001,x1,y1,z1,x2,y2,z2,....\n",
    "      sample_00002,x1,y1,z1,x2,y2,z2,....\n",
    "    \"\"\"\n",
    "    # Create output folder for CVSs.\n",
    "    if not os.path.exists(self._csvs_out_folder):\n",
    "      os.makedirs(self._csvs_out_folder)\n",
    "\n",
    "    for pose_class_name in self._pose_class_names:\n",
    "      print('Bootstrapping ', pose_class_name, file=sys.stderr)\n",
    "\n",
    "      # Paths for the pose class.\n",
    "      images_in_folder = os.path.join(self._images_in_folder, pose_class_name)\n",
    "      images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
    "      csv_out_path = os.path.join(self._csvs_out_folder, pose_class_name + '.csv')\n",
    "      if not os.path.exists(images_out_folder):\n",
    "        os.makedirs(images_out_folder)\n",
    "\n",
    "      with open(csv_out_path, 'w') as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        # Get list of images.\n",
    "        image_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
    "        if per_pose_class_limit is not None:\n",
    "          image_names = image_names[:per_pose_class_limit]\n",
    "\n",
    "        # Bootstrap every image.\n",
    "        for image_name in tqdm.tqdm(image_names):\n",
    "          # Load image.\n",
    "          input_frame = cv2.imread(os.path.join(images_in_folder, image_name))\n",
    "          input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "          # Initialize fresh pose tracker and run it.\n",
    "          with mp_pose.Pose(upper_body_only=False) as pose_tracker:\n",
    "            result = pose_tracker.process(image=input_frame)\n",
    "            pose_landmarks = result.pose_landmarks\n",
    "\n",
    "          # Save image with pose prediction (if pose was detected).\n",
    "          output_frame = input_frame.copy()\n",
    "          if pose_landmarks is not None:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=output_frame,\n",
    "                landmark_list=pose_landmarks,\n",
    "                connections=mp_pose.POSE_CONNECTIONS)\n",
    "          output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
    "          cv2.imwrite(os.path.join(images_out_folder, image_name), output_frame)\n",
    "          \n",
    "          # Save landmarks if pose was detected.\n",
    "          if pose_landmarks is not None:\n",
    "            # Get landmarks.\n",
    "            frame_height, frame_width = output_frame.shape[0], output_frame.shape[1]\n",
    "            pose_landmarks = np.array(\n",
    "                [[lmk.x * frame_width, lmk.y * frame_height, lmk.z * frame_width]\n",
    "                 for lmk in pose_landmarks.landmark],\n",
    "                dtype=np.float32)\n",
    "            assert pose_landmarks.shape == (33, 3), 'Unexpected landmarks shape: {}'.format(pose_landmarks.shape)\n",
    "            csv_out_writer.writerow([image_name] + pose_landmarks.flatten().astype(np.str).tolist())\n",
    "\n",
    "          # Draw XZ projection and concatenate with the image.\n",
    "          projection_xz = self._draw_xz_projection(\n",
    "              output_frame=output_frame, pose_landmarks=pose_landmarks)\n",
    "          output_frame = np.concatenate((output_frame, projection_xz), axis=1)\n",
    "\n",
    "  def _draw_xz_projection(self, output_frame, pose_landmarks, r=0.5, color='red'):\n",
    "    frame_height, frame_width = output_frame.shape[0], output_frame.shape[1]\n",
    "    img = Image.new('RGB', (frame_width, frame_height), color='white')\n",
    "\n",
    "    if pose_landmarks is None:\n",
    "      return np.asarray(img)\n",
    "\n",
    "    # Scale radius according to the image width.\n",
    "    r *= frame_width * 0.01\n",
    "\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for idx_1, idx_2 in mp_pose.POSE_CONNECTIONS:\n",
    "      # Flip Z and move hips center to the center of the image.\n",
    "      x1, y1, z1 = pose_landmarks[idx_1] * [1, 1, -1] + [0, 0, frame_height * 0.5]\n",
    "      x2, y2, z2 = pose_landmarks[idx_2] * [1, 1, -1] + [0, 0, frame_height * 0.5]\n",
    "\n",
    "      draw.ellipse([x1 - r, z1 - r, x1 + r, z1 + r], fill=color)\n",
    "      draw.ellipse([x2 - r, z2 - r, x2 + r, z2 + r], fill=color)\n",
    "      draw.line([x1, z1, x2, z2], width=int(r), fill=color)\n",
    "\n",
    "    return np.asarray(img)\n",
    "\n",
    "  def align_images_and_csvs(self, print_removed_items=False):\n",
    "    \"\"\"Makes sure that image folders and CSVs have the same sample.\n",
    "    \n",
    "    Leaves only intersetion of samples in both image folders and CSVs.\n",
    "    \"\"\"\n",
    "    for pose_class_name in self._pose_class_names:\n",
    "      # Paths for the pose class.\n",
    "      images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
    "      csv_out_path = os.path.join(self._csvs_out_folder, pose_class_name + '.csv')\n",
    "\n",
    "      # Read CSV into memory.\n",
    "      rows = []\n",
    "      with open(csv_out_path) as csv_out_file:\n",
    "        csv_out_reader = csv.reader(csv_out_file, delimiter=',')\n",
    "        for row in csv_out_reader:\n",
    "          rows.append(row)\n",
    "\n",
    "      # Image names left in CSV.\n",
    "      image_names_in_csv = []\n",
    "\n",
    "      # Re-write the CSV removing lines without corresponding images.\n",
    "      with open(csv_out_path, 'w') as csv_out_file:\n",
    "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        for row in rows:\n",
    "          image_name = row[0]\n",
    "          image_path = os.path.join(images_out_folder, image_name)\n",
    "          if os.path.exists(image_path):\n",
    "            image_names_in_csv.append(image_name)\n",
    "            csv_out_writer.writerow(row)\n",
    "          elif print_removed_items:\n",
    "            print('Removed image from CSV: ', image_path)\n",
    "\n",
    "      # Remove images without corresponding line in CSV.\n",
    "      for image_name in os.listdir(images_out_folder):\n",
    "        if image_name not in image_names_in_csv:\n",
    "          image_path = os.path.join(images_out_folder, image_name)\n",
    "          os.remove(image_path)\n",
    "          if print_removed_items:\n",
    "            print('Removed image from folder: ', image_path)\n",
    "\n",
    "  def analyze_outliers(self, outliers):\n",
    "    \"\"\"Classifies each sample agains all other to find outliers.\n",
    "    \n",
    "    If sample is classified differrrently than the original class - it sould\n",
    "    either be deleted or more similar samples should be aadded.\n",
    "    \"\"\"\n",
    "    for outlier in outliers:\n",
    "      image_path = os.path.join(self._images_out_folder, outlier.sample.class_name, outlier.sample.name)\n",
    "\n",
    "      print('Outlier')\n",
    "      print('  sample path =    ', image_path)\n",
    "      print('  sample class =   ', outlier.sample.class_name)\n",
    "      print('  detected class = ', outlier.detected_class)\n",
    "      print('  all classes =    ', outlier.all_classes)\n",
    "\n",
    "      img = cv2.imread(image_path)\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      show_image(img, figsize=(20, 20))\n",
    "\n",
    "  def remove_outliers(self, outliers):\n",
    "    \"\"\"Removes outliers from the image folders.\"\"\"\n",
    "    for outlier in outliers:\n",
    "      image_path = os.path.join(self._images_out_folder, outlier.sample.class_name, outlier.sample.name)\n",
    "      os.remove(image_path)\n",
    "\n",
    "  def print_images_in_statistics(self):\n",
    "    \"\"\"Prints statistics from the input image folder.\"\"\"\n",
    "    self._print_images_statistics(self._images_in_folder, self._pose_class_names)\n",
    "\n",
    "  def print_images_out_statistics(self):\n",
    "    \"\"\"Prints statistics from the output image folder.\"\"\"\n",
    "    self._print_images_statistics(self._images_out_folder, self._pose_class_names)\n",
    "\n",
    "  def _print_images_statistics(self, images_folder, pose_class_names):\n",
    "    print('Number of images per pose class:')\n",
    "    for pose_class_name in pose_class_names:\n",
    "      n_images = len([\n",
    "          n for n in os.listdir(os.path.join(images_folder, pose_class_name))\n",
    "          if not n.startswith('.')])\n",
    "      print('  {}: {}'.format(pose_class_name, n_images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
